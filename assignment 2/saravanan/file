# -*- coding: utf-8 -*-
"""Churn_Modelling Assignment 2.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/14__XymBadeFE8WuFODsJyMfeNtBo-GlD
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from google.colab import drive

drive.mount('/content/drive')

import pandas as pd
data=pd.read_csv('/content/drive/MyDrive/IBM/Churn_Modelling.csv')

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12,5))
plt.subplot(121)
sns.countplot(data['Geography'])
plt.show()

plt.figure(figsize=(18,4))
plt.plot()
sns.countplot(data['Geography'],hue=data['Gender'])
plt.show()

plt.figure(figsize=(18,4))
plt.plot()
sns.swarmplot(data['Gender'], data['CreditScore'], hue = data['HasCrCard'])
plt.show()

data.describe()

data.info()

data.isnull().sum()

data.describe()

x = data.iloc[:,:-1]
y = data.iloc[:,-1]

print(x.shape)
print(y.shape)

print(x.columns)

x = pd.get_dummies(x)
x.head()

x.shape

from sklearn import model_selection 
x_train,x_test,y_train,y_test=model_selection.train_test_split(x,y, test_size=0.2, random_state=0)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

x_train = pd.DataFrame(x_train)
x_train.head()
